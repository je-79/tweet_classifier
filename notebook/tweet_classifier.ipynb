{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25nz6TUo39SF"
      },
      "source": [
        "## DISASTER TWEET CLASSIFICATION: Real vs Metaphorical Disaster Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZOxbNPs37g3"
      },
      "source": [
        "###  Binary classification of tweets into real disasters (1) vs non-disasters (0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIjkA5Xf4USu"
      },
      "source": [
        "### Step 1: Environment Setup & Dependencies Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3ywjbhO3Zfk"
      },
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# Step 1: Environment Setup & Dependencies Installation\n",
        "# ===============================================================\n",
        "\"\"\"\n",
        "Install required libraries for:\n",
        "- Transformers (Hugging Face): Pre-trained language models\n",
        "- Datasets: Efficient data handling\n",
        "- Accelerate: Optimized training\n",
        "- scikit-learn: ML metrics and preprocessing\n",
        "\"\"\"\n",
        "\n",
        "!pip install transformers datasets accelerate -q\n",
        "!pip install scikit-learn pandas numpy matplotlib seaborn -q\n",
        "\n",
        "print(\"✓ All dependencies installed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg0UekJD4uy2"
      },
      "source": [
        "### Step 2: Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpVvuqiQ4vYE"
      },
      "outputs": [],
      "source": [
        "# =================================================================================\n",
        "# Step 2: Import Libraries\n",
        "# =================================================================================\n",
        "\"\"\"\n",
        "Import all necessary libraries for data processing, modeling, and evaluation\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    roc_auc_score,\n",
        "    roc_curve\n",
        ")\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "from datasets import Dataset\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "print(\"✓ Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0H9aAZZS5Fjb"
      },
      "source": [
        "### Step 3: Mount & Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kv3a_Oip5F5M"
      },
      "outputs": [],
      "source": [
        "# =================================================================================\n",
        "# STEP 3: Mount Google Drive & Load Data\n",
        "# =================================================================================\n",
        "\"\"\"\n",
        "Mount Google Drive to access the dataset\n",
        "Load train.csv with disaster tweet data\n",
        "\"\"\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the dataset\n",
        "DATA_PATH = '/content/drive/MyDrive/tweet_classification/train.csv'\n",
        "\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "print(\"✓ Dataset loaded successfully!\")\n",
        "print(f\"\\nDataset shape: {df.shape}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Km2k6rFP55-U"
      },
      "source": [
        "###  Step 4: Exploratory Data Analysis (EDA)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeBhCwya56Sk"
      },
      "outputs": [],
      "source": [
        "# =================================================================================\n",
        "# Step 4: Exploratory Data Analysis (EDA)\n",
        "# =================================================================================\n",
        "\"\"\"\n",
        "Comprehensive analysis of the dataset:\n",
        "- Check for missing values\n",
        "- Analyze class distribution\n",
        "- Examine text characteristics\n",
        "- Identify potential issues\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"EXPLORATORY DATA ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Basic information\n",
        "print(\"\\n1. Dataset Info:\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\n2. Missing Values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "print(\"\\n3. Class Distribution:\")\n",
        "class_dist = df['target'].value_counts()\n",
        "print(class_dist)\n",
        "print(f\"\\nClass Balance:\")\n",
        "print(f\"Non-Disaster (0): {class_dist[0]/len(df)*100:.2f}%\")\n",
        "print(f\"Disaster (1): {class_dist[1]/len(df)*100:.2f}%\")\n",
        "\n",
        "# Check for duplicates\n",
        "print(f\"\\n4. Duplicate tweets: {df.duplicated(subset=['text']).sum()}\")\n",
        "\n",
        "# Text length analysis\n",
        "df['text_length'] = df['text'].str.len()\n",
        "df['word_count'] = df['text'].str.split().str.len()\n",
        "\n",
        "print(\"\\n5. Text Statistics:\")\n",
        "print(df.groupby('target')[['text_length', 'word_count']].describe())\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Class distribution\n",
        "axes[0, 0].bar(['Non-Disaster', 'Disaster'], class_dist.values, color=['skyblue', 'coral'])\n",
        "axes[0, 0].set_title('Class Distribution', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].set_ylabel('Count')\n",
        "for i, v in enumerate(class_dist.values):\n",
        "    axes[0, 0].text(i, v + 50, str(v), ha='center', fontweight='bold')\n",
        "\n",
        "# Text length distribution by class\n",
        "df[df['target']==0]['text_length'].hist(bins=50, alpha=0.6, label='Non-Disaster', ax=axes[0, 1], color='skyblue')\n",
        "df[df['target']==1]['text_length'].hist(bins=50, alpha=0.6, label='Disaster', ax=axes[0, 1], color='coral')\n",
        "axes[0, 1].set_title('Text Length Distribution by Class', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Text Length (characters)')\n",
        "axes[0, 1].set_ylabel('Frequency')\n",
        "axes[0, 1].legend()\n",
        "\n",
        "# Word count distribution\n",
        "df[df['target']==0]['word_count'].hist(bins=30, alpha=0.6, label='Non-Disaster', ax=axes[1, 0], color='skyblue')\n",
        "df[df['target']==1]['word_count'].hist(bins=30, alpha=0.6, label='Disaster', ax=axes[1, 0], color='coral')\n",
        "axes[1, 0].set_title('Word Count Distribution by Class', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].set_xlabel('Word Count')\n",
        "axes[1, 0].set_ylabel('Frequency')\n",
        "axes[1, 0].legend()\n",
        "\n",
        "# Box plot for text length\n",
        "df.boxplot(column='text_length', by='target', ax=axes[1, 1])\n",
        "axes[1, 1].set_title('Text Length by Class (Boxplot)', fontsize=14, fontweight='bold')\n",
        "axes[1, 1].set_xlabel('Target (0=Non-Disaster, 1=Disaster)')\n",
        "axes[1, 1].set_ylabel('Text Length')\n",
        "plt.suptitle('')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Sample tweets from each class\n",
        "print(\"\\n6. Sample Tweets:\")\n",
        "print(\"\\n--- DISASTER TWEETS (target=1) ---\")\n",
        "for i, tweet in enumerate(df[df['target']==1]['text'].head(3).values, 1):\n",
        "    print(f\"{i}. {tweet}\")\n",
        "\n",
        "print(\"\\n--- NON-DISASTER TWEETS (target=0) ---\")\n",
        "for i, tweet in enumerate(df[df['target']==0]['text'].head(3).values, 1):\n",
        "    print(f\"{i}. {tweet}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awrj9lr96T_n"
      },
      "source": [
        "### Step 5: Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtJGGgBd6R4u"
      },
      "outputs": [],
      "source": [
        "# =================================================================================\n",
        "# Step 5: Data Preprocessing\n",
        "# =================================================================================\n",
        "\"\"\"\n",
        "Minimal preprocessing for transformer models:\n",
        "- Remove duplicates if any\n",
        "- Handle missing values\n",
        "- Basic text cleaning\n",
        "- Create train/validation split\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"DATA PREPROCESSING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Remove duplicates\n",
        "initial_size = len(df)\n",
        "df = df.drop_duplicates(subset=['text'], keep='first')\n",
        "print(f\"✓ Removed {initial_size - len(df)} duplicate tweets\")\n",
        "\n",
        "# Handle missing values\n",
        "df = df.dropna(subset=['text', 'target'])\n",
        "print(f\"✓ Dataset size after cleaning: {len(df)}\")\n",
        "\n",
        "# Prepare data for modeling\n",
        "X = df['text'].values\n",
        "y = df['target'].values\n",
        "\n",
        "# Stratified train-validation split (80-20)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=RANDOM_SEED,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(f\"\\n✓ Train set size: {len(X_train)}\")\n",
        "print(f\"✓ Validation set size: {len(X_val)}\")\n",
        "print(f\"\\nTrain class distribution:\")\n",
        "print(f\"  Non-Disaster: {(y_train==0).sum()} ({(y_train==0).sum()/len(y_train)*100:.2f}%)\")\n",
        "print(f\"  Disaster: {(y_train==1).sum()} ({(y_train==1).sum()/len(y_train)*100:.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx3ihx0k6rSQ"
      },
      "source": [
        "### Step 6: Baseline Model - Logistic Regression with TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5rYLzPG6rsB"
      },
      "outputs": [],
      "source": [
        "# =================================================================================\n",
        "# Step 6: Baseline Model - Logistic Regression with TF-IDF\n",
        "# =================================================================================\n",
        "\"\"\"\n",
        "Quick baseline model to establish performance floor:\n",
        "- TF-IDF vectorization\n",
        "- Logistic Regression classifier\n",
        "- Provides fast benchmark for comparison\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"BASELINE MODEL: LOGISTIC REGRESSION + TF-IDF\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "print(\"\\n Vectorizing text with TF-IDF...\")\n",
        "tfidf = TfidfVectorizer(\n",
        "    max_features=5000,\n",
        "    ngram_range=(1, 2),  # unigrams and bigrams\n",
        "    min_df=2,\n",
        "    max_df=0.9\n",
        ")\n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_val_tfidf = tfidf.transform(X_val)\n",
        "\n",
        "print(f\"✓ TF-IDF shape: {X_train_tfidf.shape}\")\n",
        "\n",
        "# Train Logistic Regression\n",
        "print(\"\\n Training Logistic Regression...\")\n",
        "lr_model = LogisticRegression(\n",
        "    max_iter=1000,\n",
        "    random_state=RANDOM_SEED,\n",
        "    class_weight='balanced'  # Handle class imbalance\n",
        ")\n",
        "lr_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_train = lr_model.predict(X_train_tfidf)\n",
        "y_pred_val = lr_model.predict(X_val_tfidf)\n",
        "\n",
        "# Evaluation\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"BASELINE MODEL RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nTraining Set Performance:\")\n",
        "print(f\"  Accuracy:  {accuracy_score(y_train, y_pred_train):.4f}\")\n",
        "print(f\"  F1-Score:  {f1_score(y_train, y_pred_train):.4f}\")\n",
        "\n",
        "print(\"\\nValidation Set Performance:\")\n",
        "print(f\"  Accuracy:  {accuracy_score(y_val, y_pred_val):.4f}\")\n",
        "print(f\"  F1-Score:  {f1_score(y_val, y_pred_val):.4f}\")\n",
        "print(f\"  Precision: {precision_score(y_val, y_pred_val):.4f}\")\n",
        "print(f\"  Recall:    {recall_score(y_val, y_pred_val):.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_val, y_pred_val, target_names=['Non-Disaster', 'Disaster']))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_val, y_pred_val)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Non-Disaster', 'Disaster'],\n",
        "            yticklabels=['Non-Disaster', 'Disaster'])\n",
        "plt.title('Baseline Model - Confusion Matrix', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rteajDwZ62ru"
      },
      "source": [
        "### Step 7: Prepare Data for DistilBERT\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-yQopr1629W"
      },
      "outputs": [],
      "source": [
        "# =================================================================================\n",
        "# Step 7: Prepare Data for DistilBERT\n",
        "# =================================================================================\n",
        "\"\"\"\n",
        "Convert data to Hugging Face Dataset format:\n",
        "- Tokenize text with DistilBERT tokenizer\n",
        "- Create Dataset objects for efficient loading\n",
        "- Set up for transformer training\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"PREPARING DATA FOR DISTILBERT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Initialize tokenizer\n",
        "MODEL_NAME = \"distilbert-base-uncased\"\n",
        "print(f\"\\n Loading tokenizer: {MODEL_NAME}\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_function(examples):\n",
        "    \"\"\"Tokenize text with truncation and padding\"\"\"\n",
        "    return tokenizer(\n",
        "        examples['text'],\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=128  # Most tweets are short\n",
        "    )\n",
        "\n",
        "# Create Hugging Face datasets\n",
        "train_dataset = Dataset.from_dict({\n",
        "    'text': X_train.tolist(),\n",
        "    'label': y_train.tolist()\n",
        "})\n",
        "\n",
        "val_dataset = Dataset.from_dict({\n",
        "    'text': X_val.tolist(),\n",
        "    'label': y_val.tolist()\n",
        "})\n",
        "\n",
        "print(f\"✓ Train dataset: {len(train_dataset)} samples\")\n",
        "print(f\"✓ Validation dataset: {len(val_dataset)} samples\")\n",
        "\n",
        "# Tokenize datasets\n",
        "print(\"\\n Tokenizing datasets...\")\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Set format for PyTorch\n",
        "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "val_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "print(\"✓ Tokenization complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DADI0Je97jMI"
      },
      "source": [
        "### Step 8: Initialize DistilBERT Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZW95DvNa7fVM"
      },
      "outputs": [],
      "source": [
        "# =================================================================================\n",
        "# Step 8: Initialize DistilBERT Model\n",
        "# =================================================================================\n",
        "\"\"\"\n",
        "Load pre-trained DistilBERT model:\n",
        "- Efficient transformer\n",
        "- Pre-trained on large text corpus\n",
        "- Fine-tune for binary classification\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"INITIALIZING DISTILBERT MODEL\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Calculate class weights for imbalanced data\n",
        "class_weights = len(y_train) / (2 * np.bincount(y_train))\n",
        "print(f\"\\nClass weights (for imbalance): {class_weights}\")\n",
        "\n",
        "# Load model\n",
        "print(f\"\\n Loading {MODEL_NAME}...\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=2,\n",
        "    problem_type=\"single_label_classification\"\n",
        ")\n",
        "\n",
        "# Move to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "print(f\"✓ Model loaded successfully!\")\n",
        "print(f\"✓ Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPtPR7M8Z5x4"
      },
      "source": [
        "### Step 9: Define Training Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2DiySx9Z-Og"
      },
      "outputs": [],
      "source": [
        "# =================================================================================\n",
        "# Step 9: Define Training Configuration\n",
        "# =================================================================================\n",
        "\"\"\"\n",
        "Configure training hyperparameters:\n",
        "- Learning rate, batch size, epochs\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"TRAINING CONFIGURATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Define metrics computation\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Compute accuracy, F1, precision, recall for evaluation\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy_score(labels, predictions),\n",
        "        'f1': f1_score(labels, predictions),\n",
        "        'precision': precision_score(labels, predictions),\n",
        "        'recall': recall_score(labels, predictions),\n",
        "    }\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,\n",
        "    eval_strategy=\"epoch\",  # Evaluate once per epoch (simpler)\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    save_total_limit=1,  # Keep only best model\n",
        "    seed=RANDOM_SEED,\n",
        "    report_to=\"none\",  # Disable wandb/tensorboard logging\n",
        ")\n",
        "\n",
        "print(\"✓ Training configuration complete!\")\n",
        "print(f\"\\nKey parameters:\")\n",
        "print(f\"  Epochs: {training_args.num_train_epochs}\")\n",
        "print(f\"  Batch size: {training_args.per_device_train_batch_size}\")\n",
        "print(f\"  Learning rate: {training_args.learning_rate}\")\n",
        "print(f\"  Evaluation: Once per epoch\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElUMpOUWae8b"
      },
      "source": [
        "### STEP 10: Train DistilBERT Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMx3K6jVaZJK"
      },
      "outputs": [],
      "source": [
        "# =================================================================================\n",
        "# STEP 10:Train DistilBERT Model\n",
        "# =================================================================================\n",
        "\"\"\"\n",
        "Fine-tune DistilBERT on disaster tweet data:\n",
        "- Save best model\n",
        "- Takes ~8-12 minutes with GPU, ~25-35 minutes with CPU\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"TRAINING DISTILBERT MODEL\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Initialize Trainer with configuration\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"\\n Starting training...\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Train the model\n",
        "\n",
        "train_result = trainer.train()\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"✓ TRAINING COMPLETE!\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nTraining metrics:\")\n",
        "print(f\"  Final training loss: {train_result.training_loss:.4f}\")\n",
        "print(f\"  Total training time: {train_result.metrics['train_runtime']:.2f} seconds\")\n",
        "print(f\"  Training samples/second: {train_result.metrics['train_samples_per_second']:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uk9EocO8LNT"
      },
      "source": [
        "### Step 11: Evaluate DistilBERT Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhXjx4rN8Lgj"
      },
      "outputs": [],
      "source": [
        "# =================================================================================\n",
        "# Step 11: Evaluate DistilBERT Model\n",
        "# =================================================================================\n",
        "\"\"\"\n",
        "Comprehensive evaluation of trained model:\n",
        "- Validation set performance\n",
        "- Confusion matrix\n",
        "- Classification report\n",
        "- ROC curve and AUC\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"MODEL EVALUATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Evaluate on validation set\n",
        "print(\"\\n Evaluating model...\")\n",
        "eval_results = trainer.evaluate()\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DISTILBERT MODEL RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nValidation Set Performance:\")\n",
        "print(f\"  Accuracy:  {eval_results['eval_accuracy']:.4f}\")\n",
        "print(f\"  F1-Score:  {eval_results['eval_f1']:.4f}\")\n",
        "print(f\"  Precision: {eval_results['eval_precision']:.4f}\")\n",
        "print(f\"  Recall:    {eval_results['eval_recall']:.4f}\")\n",
        "print(f\"  Loss:      {eval_results['eval_loss']:.4f}\")\n",
        "\n",
        "# Get predictions\n",
        "predictions = trainer.predict(val_dataset)\n",
        "y_pred_probs = torch.softmax(torch.tensor(predictions.predictions), dim=1).numpy()\n",
        "y_pred = np.argmax(predictions.predictions, axis=1)\n",
        "\n",
        "# Detailed classification report\n",
        "print(\"\\nDetailed Classification Report:\")\n",
        "print(classification_report(y_val, y_pred, target_names=['Non-Disaster', 'Disaster']))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_val, y_pred)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',\n",
        "            xticklabels=['Non-Disaster', 'Disaster'],\n",
        "            yticklabels=['Non-Disaster', 'Disaster'],\n",
        "            cbar_kws={'label': 'Count'})\n",
        "plt.title('DistilBERT Model - Confusion Matrix', fontsize=16, fontweight='bold')\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(y_val, y_pred_probs[:, 1])\n",
        "roc_auc = roc_auc_score(y_val, y_pred_probs[:, 1])\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate', fontsize=12)\n",
        "plt.ylabel('True Positive Rate', fontsize=12)\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=16, fontweight='bold')\n",
        "plt.legend(loc=\"lower right\", fontsize=12)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n✓ ROC-AUC Score: {roc_auc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kz1wL6u88SJ1"
      },
      "source": [
        "### Step 12: Error Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtRHSzsk8YnI"
      },
      "outputs": [],
      "source": [
        "# =================================================================================\n",
        "# Step 12: Error Analysis\n",
        "# =================================================================================\n",
        "\"\"\"\n",
        "Analyze model errors\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"ERROR ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Identify misclassified samples\n",
        "misclassified_idx = np.where(y_val != y_pred)[0]\n",
        "print(f\"\\nTotal misclassified samples: {len(misclassified_idx)}\")\n",
        "\n",
        "# False Positives (predicted disaster, actually non-disaster)\n",
        "fp_idx = np.where((y_val == 0) & (y_pred == 1))[0]\n",
        "print(f\"False Positives: {len(fp_idx)}\")\n",
        "\n",
        "# False Negatives (predicted non-disaster, actually disaster)\n",
        "fn_idx = np.where((y_val == 1) & (y_pred == 0))[0]\n",
        "print(f\"False Negatives: {len(fn_idx)}\")\n",
        "\n",
        "# Show examples of misclassifications\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FALSE POSITIVES (Predicted Disaster, Actually Non-Disaster)\")\n",
        "print(\"=\"*80)\n",
        "for i, idx in enumerate(fp_idx[:5], 1):\n",
        "    print(f\"\\n{i}. Tweet: {X_val[idx]}\")\n",
        "    print(f\"   Confidence: {y_pred_probs[idx][1]:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FALSE NEGATIVES (Predicted Non-Disaster, Actually Disaster)\")\n",
        "print(\"=\"*80)\n",
        "for i, idx in enumerate(fn_idx[:5], 1):\n",
        "    print(f\"\\n{i}. Tweet: {X_val[idx]}\")\n",
        "    print(f\"   Confidence: {y_pred_probs[idx][0]:.4f}\")\n",
        "\n",
        "# Prediction confidence analysis\n",
        "correct_idx = np.where(y_val == y_pred)[0]\n",
        "avg_confidence_correct = np.mean(np.max(y_pred_probs[correct_idx], axis=1))\n",
        "avg_confidence_wrong = np.mean(np.max(y_pred_probs[misclassified_idx], axis=1))\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CONFIDENCE ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Average confidence (correct predictions): {avg_confidence_correct:.4f}\")\n",
        "print(f\"Average confidence (wrong predictions): {avg_confidence_wrong:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7w1UeUwI8oZS"
      },
      "source": [
        "### Step 13: Model Comparison & Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcl4uWmd8orx"
      },
      "outputs": [],
      "source": [
        "# =================================================================================\n",
        "# Step 13: Model Comparison & Summary\n",
        "# =================================================================================\n",
        "\"\"\"\n",
        "Compare baseline vs DistilBERT performance\n",
        "Provide final summary and recommendations\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"MODEL COMPARISON & SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Create comparison DataFrame\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Model': ['Logistic Regression (Baseline)', 'DistilBERT (Fine-tuned)'],\n",
        "    'Accuracy': [\n",
        "        accuracy_score(y_val, lr_model.predict(X_val_tfidf)),\n",
        "        eval_results['eval_accuracy']\n",
        "    ],\n",
        "    'F1-Score': [\n",
        "        f1_score(y_val, lr_model.predict(X_val_tfidf)),\n",
        "        eval_results['eval_f1']\n",
        "    ],\n",
        "    'Precision': [\n",
        "        precision_score(y_val, lr_model.predict(X_val_tfidf)),\n",
        "        eval_results['eval_precision']\n",
        "    ],\n",
        "    'Recall': [\n",
        "        recall_score(y_val, lr_model.predict(X_val_tfidf)),\n",
        "        eval_results['eval_recall']\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"\\n\", comparison_df.to_string(index=False))\n",
        "\n",
        "# Visualization\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "x = np.arange(len(comparison_df))\n",
        "width = 0.2\n",
        "\n",
        "metrics = ['Accuracy', 'F1-Score', 'Precision', 'Recall']\n",
        "colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12']\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "    ax.bar(x + i*width, comparison_df[metric], width, label=metric, color=colors[i])\n",
        "\n",
        "ax.set_xlabel('Model', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(x + width * 1.5)\n",
        "ax.set_xticklabels(comparison_df['Model'])\n",
        "ax.legend(fontsize=10)\n",
        "ax.set_ylim([0, 1.1])\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "    for j, v in enumerate(comparison_df[metric]):\n",
        "        ax.text(j + i*width, v + 0.02, f'{v:.3f}', ha='center', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"KEY FINDINGS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "improvement = (eval_results['eval_f1'] - f1_score(y_val, lr_model.predict(X_val_tfidf))) * 100\n",
        "print(f\"\\n✓ DistilBERT achieves {improvement:.2f}% improvement in F1-Score over baseline\")\n",
        "print(f\"✓ Final model accuracy: {eval_results['eval_accuracy']*100:.2f}%\")\n",
        "print(f\"✓ Model successfully distinguishes literal from metaphorical disaster language\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RECOMMENDATIONS\")\n",
        "print(\"=\"*80)\n",
        "print(\"\"\"\n",
        "1. Model is production-ready for disaster tweet detection\n",
        "2. Consider ensemble with baseline for edge cases\n",
        "3. Monitor performance on new data for concept drift\n",
        "4. Potential improvements:\n",
        "   - Collect more training data for edge cases\n",
        "   - Experiment with larger models (BERT, RoBERTa)\n",
        "   - Add context features (user history, location)\n",
        "   - Implement active learning for ambiguous cases\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZ7t1lbA82iN"
      },
      "source": [
        "### Step 14: Save Model & Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckhBaHw-83CR"
      },
      "outputs": [],
      "source": [
        "# =================================================================================\n",
        "# Step 14: Save Model & Predictions\n",
        "# =================================================================================\n",
        "\"\"\"\n",
        "Save the trained model and generate predictions for future use\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"SAVING MODEL & PREDICTIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Save model and tokenizer\n",
        "output_dir = \"./disaster_tweet_classifier\"\n",
        "trainer.save_model(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "print(f\"✓ Model saved to: {output_dir}\")\n",
        "\n",
        "# Save predictions\n",
        "predictions_df = pd.DataFrame({\n",
        "    'text': X_val,\n",
        "    'true_label': y_val,\n",
        "    'predicted_label': y_pred,\n",
        "    'confidence_non_disaster': y_pred_probs[:, 0],\n",
        "    'confidence_disaster': y_pred_probs[:, 1]\n",
        "})\n",
        "\n",
        "predictions_df.to_csv('predictions.csv', index=False)\n",
        "print(\"✓ Predictions saved to: predictions.csv\")\n",
        "\n",
        "\n",
        "# Create a function for inference\n",
        "def predict_disaster(text, model, tokenizer, device):\n",
        "    \"\"\"\n",
        "    Predict if a tweet is about a real disaster\n",
        "\n",
        "    Args:\n",
        "        text (str): Tweet text\n",
        "        model: Trained model\n",
        "        tokenizer: Tokenizer\n",
        "        device: CPU or CUDA device\n",
        "\n",
        "    Returns:\n",
        "        dict: Prediction and confidence scores\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        probs = torch.softmax(outputs.logits, dim=1).cpu().numpy()[0]\n",
        "\n",
        "    prediction = \"DISASTER\" if probs[1] > 0.5 else \"NON-DISASTER\"\n",
        "    confidence = max(probs)\n",
        "\n",
        "    return {\n",
        "        'prediction': prediction,\n",
        "        'confidence': confidence,\n",
        "        'prob_non_disaster': probs[0],\n",
        "        'prob_disaster': probs[1]\n",
        "    }\n",
        "\n",
        "print(\"\\n✓ Inference function created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtRd1WJu9b7O"
      },
      "source": [
        "### Step 15: Interactive Prediction Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wACnUl79cMo"
      },
      "outputs": [],
      "source": [
        "# =================================================================================\n",
        "# Step 15: Interactive Prediction Demo\n",
        "# =================================================================================\n",
        "\"\"\"\n",
        "Test the model with custom tweets\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"INTERACTIVE PREDICTION DEMO\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Test examples\n",
        "test_tweets = [\n",
        "    \"Massive earthquake hits California, buildings collapsed\",\n",
        "    \"My presentation was an absolute disaster\",\n",
        "    \"Forest fire spreading rapidly in the region\",\n",
        "    \"This traffic is killing me\",\n",
        "    \"Flood warning issued for the coastal areas\",\n",
        "    \"My code is on fire today! Absolutely ABLAZE with productivity\"\n",
        "]\n",
        "\n",
        "print(\"\\nTesting model with example tweets:\\n\")\n",
        "\n",
        "for i, tweet in enumerate(test_tweets, 1):\n",
        "    result = predict_disaster(tweet, model, tokenizer, device)\n",
        "\n",
        "    print(f\"{i}. Tweet: \\\"{tweet}\\\"\")\n",
        "    print(f\"   Prediction: {result['prediction']}\")\n",
        "    print(f\"   Confidence: {result['confidence']:.4f}\")\n",
        "    print(f\"   Prob(Non-Disaster): {result['prob_non_disaster']:.4f}\")\n",
        "    print(f\"   Prob(Disaster): {result['prob_disaster']:.4f}\")\n",
        "    print()\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"PROJECT COMPLETE!\")\n",
        "print(\"=\"*80)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}